


import requests
from bs4 import BeautifulSoup
import csv

def scrape_weather_data(city):
    # Replace this URL with the actual weather website you want to scrape
    url = f'https://www.weather.com/en-IN/weather/today/l/{city}'

    # Send a GET request to the weather website
    response = requests.get(url)

    if response.status_code == 200:
        # Parse the HTML content of the page
        soup = BeautifulSoup(response.text, 'html.parser')

        # Extract temperature and humidity information (replace these with actual HTML tags)
        temperature = soup.find('span', {'class': 'CurrentConditions--tempValue--3KcTQ'}).text
        humidity = soup.find('div', {'data-testid': 'PercentageValue'}).text

        # Create a list of dictionaries with the scraped data
        weather_data = [{'City': city, 'Temperature': temperature, 'Humidity': humidity}]

        # Save the data to a CSV file
        csv_filename = 'weather_data.csv'
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:
            fieldnames = ['City', 'Temperature', 'Humidity']
            csv_writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
            csv_writer.writeheader()
            csv_writer.writerows(weather_data)

        # Print the extracted data
        print(f'Data saved to {csv_filename}:')
        print(f'City: {city}, Temperature: {temperature}, Humidity: {humidity}')

    else:
        print(f'Error: {response.status_code}')

# Example usage
city_to_search = 'new-york'
scrape_weather_data(city_to_search)






